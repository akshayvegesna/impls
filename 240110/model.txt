>> transformer.wte.weight torch.Size([49152, 2048])
>> transformer.wpe.weight torch.Size([8192, 2048])
>> transformer.h.0.ln_1.weight torch.Size([2048])
>> transformer.h.0.ln_1.bias torch.Size([2048])
>> transformer.h.0.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.0.attn.c_attn.bias torch.Size([2304])
>> transformer.h.0.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.0.attn.c_proj.bias torch.Size([2048])
>> transformer.h.0.ln_2.weight torch.Size([2048])
>> transformer.h.0.ln_2.bias torch.Size([2048])
>> transformer.h.0.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.0.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.0.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.0.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.1.ln_1.weight torch.Size([2048])
>> transformer.h.1.ln_1.bias torch.Size([2048])
>> transformer.h.1.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.1.attn.c_attn.bias torch.Size([2304])
>> transformer.h.1.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.1.attn.c_proj.bias torch.Size([2048])
>> transformer.h.1.ln_2.weight torch.Size([2048])
>> transformer.h.1.ln_2.bias torch.Size([2048])
>> transformer.h.1.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.1.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.1.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.1.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.2.ln_1.weight torch.Size([2048])
>> transformer.h.2.ln_1.bias torch.Size([2048])
>> transformer.h.2.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.2.attn.c_attn.bias torch.Size([2304])
>> transformer.h.2.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.2.attn.c_proj.bias torch.Size([2048])
>> transformer.h.2.ln_2.weight torch.Size([2048])
>> transformer.h.2.ln_2.bias torch.Size([2048])
>> transformer.h.2.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.2.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.2.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.2.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.3.ln_1.weight torch.Size([2048])
>> transformer.h.3.ln_1.bias torch.Size([2048])
>> transformer.h.3.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.3.attn.c_attn.bias torch.Size([2304])
>> transformer.h.3.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.3.attn.c_proj.bias torch.Size([2048])
>> transformer.h.3.ln_2.weight torch.Size([2048])
>> transformer.h.3.ln_2.bias torch.Size([2048])
>> transformer.h.3.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.3.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.3.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.3.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.4.ln_1.weight torch.Size([2048])
>> transformer.h.4.ln_1.bias torch.Size([2048])
>> transformer.h.4.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.4.attn.c_attn.bias torch.Size([2304])
>> transformer.h.4.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.4.attn.c_proj.bias torch.Size([2048])
>> transformer.h.4.ln_2.weight torch.Size([2048])
>> transformer.h.4.ln_2.bias torch.Size([2048])
>> transformer.h.4.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.4.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.4.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.4.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.5.ln_1.weight torch.Size([2048])
>> transformer.h.5.ln_1.bias torch.Size([2048])
>> transformer.h.5.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.5.attn.c_attn.bias torch.Size([2304])
>> transformer.h.5.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.5.attn.c_proj.bias torch.Size([2048])
>> transformer.h.5.ln_2.weight torch.Size([2048])
>> transformer.h.5.ln_2.bias torch.Size([2048])
>> transformer.h.5.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.5.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.5.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.5.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.6.ln_1.weight torch.Size([2048])
>> transformer.h.6.ln_1.bias torch.Size([2048])
>> transformer.h.6.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.6.attn.c_attn.bias torch.Size([2304])
>> transformer.h.6.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.6.attn.c_proj.bias torch.Size([2048])
>> transformer.h.6.ln_2.weight torch.Size([2048])
>> transformer.h.6.ln_2.bias torch.Size([2048])
>> transformer.h.6.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.6.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.6.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.6.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.7.ln_1.weight torch.Size([2048])
>> transformer.h.7.ln_1.bias torch.Size([2048])
>> transformer.h.7.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.7.attn.c_attn.bias torch.Size([2304])
>> transformer.h.7.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.7.attn.c_proj.bias torch.Size([2048])
>> transformer.h.7.ln_2.weight torch.Size([2048])
>> transformer.h.7.ln_2.bias torch.Size([2048])
>> transformer.h.7.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.7.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.7.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.7.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.8.ln_1.weight torch.Size([2048])
>> transformer.h.8.ln_1.bias torch.Size([2048])
>> transformer.h.8.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.8.attn.c_attn.bias torch.Size([2304])
>> transformer.h.8.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.8.attn.c_proj.bias torch.Size([2048])
>> transformer.h.8.ln_2.weight torch.Size([2048])
>> transformer.h.8.ln_2.bias torch.Size([2048])
>> transformer.h.8.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.8.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.8.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.8.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.9.ln_1.weight torch.Size([2048])
>> transformer.h.9.ln_1.bias torch.Size([2048])
>> transformer.h.9.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.9.attn.c_attn.bias torch.Size([2304])
>> transformer.h.9.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.9.attn.c_proj.bias torch.Size([2048])
>> transformer.h.9.ln_2.weight torch.Size([2048])
>> transformer.h.9.ln_2.bias torch.Size([2048])
>> transformer.h.9.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.9.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.9.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.9.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.10.ln_1.weight torch.Size([2048])
>> transformer.h.10.ln_1.bias torch.Size([2048])
>> transformer.h.10.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.10.attn.c_attn.bias torch.Size([2304])
>> transformer.h.10.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.10.attn.c_proj.bias torch.Size([2048])
>> transformer.h.10.ln_2.weight torch.Size([2048])
>> transformer.h.10.ln_2.bias torch.Size([2048])
>> transformer.h.10.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.10.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.10.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.10.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.11.ln_1.weight torch.Size([2048])
>> transformer.h.11.ln_1.bias torch.Size([2048])
>> transformer.h.11.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.11.attn.c_attn.bias torch.Size([2304])
>> transformer.h.11.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.11.attn.c_proj.bias torch.Size([2048])
>> transformer.h.11.ln_2.weight torch.Size([2048])
>> transformer.h.11.ln_2.bias torch.Size([2048])
>> transformer.h.11.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.11.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.11.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.11.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.12.ln_1.weight torch.Size([2048])
>> transformer.h.12.ln_1.bias torch.Size([2048])
>> transformer.h.12.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.12.attn.c_attn.bias torch.Size([2304])
>> transformer.h.12.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.12.attn.c_proj.bias torch.Size([2048])
>> transformer.h.12.ln_2.weight torch.Size([2048])
>> transformer.h.12.ln_2.bias torch.Size([2048])
>> transformer.h.12.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.12.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.12.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.12.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.13.ln_1.weight torch.Size([2048])
>> transformer.h.13.ln_1.bias torch.Size([2048])
>> transformer.h.13.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.13.attn.c_attn.bias torch.Size([2304])
>> transformer.h.13.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.13.attn.c_proj.bias torch.Size([2048])
>> transformer.h.13.ln_2.weight torch.Size([2048])
>> transformer.h.13.ln_2.bias torch.Size([2048])
>> transformer.h.13.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.13.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.13.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.13.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.14.ln_1.weight torch.Size([2048])
>> transformer.h.14.ln_1.bias torch.Size([2048])
>> transformer.h.14.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.14.attn.c_attn.bias torch.Size([2304])
>> transformer.h.14.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.14.attn.c_proj.bias torch.Size([2048])
>> transformer.h.14.ln_2.weight torch.Size([2048])
>> transformer.h.14.ln_2.bias torch.Size([2048])
>> transformer.h.14.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.14.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.14.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.14.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.15.ln_1.weight torch.Size([2048])
>> transformer.h.15.ln_1.bias torch.Size([2048])
>> transformer.h.15.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.15.attn.c_attn.bias torch.Size([2304])
>> transformer.h.15.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.15.attn.c_proj.bias torch.Size([2048])
>> transformer.h.15.ln_2.weight torch.Size([2048])
>> transformer.h.15.ln_2.bias torch.Size([2048])
>> transformer.h.15.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.15.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.15.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.15.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.16.ln_1.weight torch.Size([2048])
>> transformer.h.16.ln_1.bias torch.Size([2048])
>> transformer.h.16.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.16.attn.c_attn.bias torch.Size([2304])
>> transformer.h.16.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.16.attn.c_proj.bias torch.Size([2048])
>> transformer.h.16.ln_2.weight torch.Size([2048])
>> transformer.h.16.ln_2.bias torch.Size([2048])
>> transformer.h.16.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.16.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.16.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.16.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.17.ln_1.weight torch.Size([2048])
>> transformer.h.17.ln_1.bias torch.Size([2048])
>> transformer.h.17.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.17.attn.c_attn.bias torch.Size([2304])
>> transformer.h.17.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.17.attn.c_proj.bias torch.Size([2048])
>> transformer.h.17.ln_2.weight torch.Size([2048])
>> transformer.h.17.ln_2.bias torch.Size([2048])
>> transformer.h.17.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.17.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.17.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.17.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.18.ln_1.weight torch.Size([2048])
>> transformer.h.18.ln_1.bias torch.Size([2048])
>> transformer.h.18.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.18.attn.c_attn.bias torch.Size([2304])
>> transformer.h.18.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.18.attn.c_proj.bias torch.Size([2048])
>> transformer.h.18.ln_2.weight torch.Size([2048])
>> transformer.h.18.ln_2.bias torch.Size([2048])
>> transformer.h.18.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.18.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.18.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.18.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.19.ln_1.weight torch.Size([2048])
>> transformer.h.19.ln_1.bias torch.Size([2048])
>> transformer.h.19.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.19.attn.c_attn.bias torch.Size([2304])
>> transformer.h.19.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.19.attn.c_proj.bias torch.Size([2048])
>> transformer.h.19.ln_2.weight torch.Size([2048])
>> transformer.h.19.ln_2.bias torch.Size([2048])
>> transformer.h.19.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.19.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.19.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.19.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.20.ln_1.weight torch.Size([2048])
>> transformer.h.20.ln_1.bias torch.Size([2048])
>> transformer.h.20.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.20.attn.c_attn.bias torch.Size([2304])
>> transformer.h.20.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.20.attn.c_proj.bias torch.Size([2048])
>> transformer.h.20.ln_2.weight torch.Size([2048])
>> transformer.h.20.ln_2.bias torch.Size([2048])
>> transformer.h.20.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.20.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.20.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.20.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.21.ln_1.weight torch.Size([2048])
>> transformer.h.21.ln_1.bias torch.Size([2048])
>> transformer.h.21.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.21.attn.c_attn.bias torch.Size([2304])
>> transformer.h.21.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.21.attn.c_proj.bias torch.Size([2048])
>> transformer.h.21.ln_2.weight torch.Size([2048])
>> transformer.h.21.ln_2.bias torch.Size([2048])
>> transformer.h.21.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.21.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.21.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.21.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.22.ln_1.weight torch.Size([2048])
>> transformer.h.22.ln_1.bias torch.Size([2048])
>> transformer.h.22.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.22.attn.c_attn.bias torch.Size([2304])
>> transformer.h.22.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.22.attn.c_proj.bias torch.Size([2048])
>> transformer.h.22.ln_2.weight torch.Size([2048])
>> transformer.h.22.ln_2.bias torch.Size([2048])
>> transformer.h.22.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.22.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.22.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.22.mlp.c_proj.bias torch.Size([2048])
>> transformer.h.23.ln_1.weight torch.Size([2048])
>> transformer.h.23.ln_1.bias torch.Size([2048])
>> transformer.h.23.attn.c_attn.weight torch.Size([2304, 2048])
>> transformer.h.23.attn.c_attn.bias torch.Size([2304])
>> transformer.h.23.attn.c_proj.weight torch.Size([2048, 2048])
>> transformer.h.23.attn.c_proj.bias torch.Size([2048])
>> transformer.h.23.ln_2.weight torch.Size([2048])
>> transformer.h.23.ln_2.bias torch.Size([2048])
>> transformer.h.23.mlp.c_fc.weight torch.Size([8192, 2048])
>> transformer.h.23.mlp.c_fc.bias torch.Size([8192])
>> transformer.h.23.mlp.c_proj.weight torch.Size([2048, 8192])
>> transformer.h.23.mlp.c_proj.bias torch.Size([2048])
>> transformer.ln_f.weight torch.Size([2048])
>> transformer.ln_f.bias torch.Size([2048])
>> lm_head.weight torch.Size([49152, 2048])

GPTBigCodeConfig {
  "_name_or_path": "bigcode/starcoderbase-1b",
  "activation_function": "gelu_pytorch_tanh",
  "architectures": [
    "GPTBigCodeForCausalLM"
  ],
  "attention_softmax_in_fp32": true,
  "attn_pdrop": 0.1,
  "bos_token_id": 0,
  "embd_pdrop": 0.1,
  "eos_token_id": 0,
  "inference_runner": 0,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "max_batch_size": null,
  "max_sequence_length": null,
  "model_type": "gpt_bigcode",
  "multi_query": true,
  "n_embd": 2048,
  "n_head": 16,
  "n_inner": 8192,
  "n_layer": 24,
  "n_positions": 8192,
  "pad_key_length": true,
  "pre_allocate_kv_cache": false,
  "resid_pdrop": 0.1,
  "scale_attention_softmax_in_fp32": true,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "torch_dtype": "float32",
  "transformers_version": "4.36.2",
  "use_cache": true,
  "validate_runner_input": true,
  "vocab_size": 49152
}


